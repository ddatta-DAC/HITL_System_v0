{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "massive-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('./../..')\n",
    "sys.path.append('./..')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append('./../..')\n",
    "from redisStore import redisUtil\n",
    "from pathlib import Path\n",
    "import plotly\n",
    "from plotly import express as px\n",
    "import os\n",
    "import plotly.io as pio\n",
    "import pickle\n",
    "from DB_Ingestion.sqlite_engine import sqlite\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from sqlalchemy import create_engine\n",
    "from plotly import io\n",
    "from plotly import express as px\n",
    "from plotly.graph_objs import Layout\n",
    "\n",
    "DATA_LOC = None\n",
    "subDIR = None\n",
    "# Singleton object\n",
    "redis_obj = redisUtil.redisStore\n",
    "EMB_DIM = None\n",
    "htmlSaveDir = None\n",
    "SQL_Conn = None\n",
    "reference_df = None\n",
    "\n",
    "# =============================\n",
    "#  This needs to be called to ingest data into redis,\n",
    "# =============================\n",
    "def initialize(\n",
    "    _DATA_LOC,\n",
    "    _subDIR,\n",
    "    mp2v_emb_dir = './../records2graph/saved_model_data',\n",
    "    emb_dim = 64,\n",
    "    _htmlSaveDir = None\n",
    "):\n",
    "    global redis_obj\n",
    "    global DATA_LOC\n",
    "    global subDIR\n",
    "    global EMB_DIM\n",
    "    global htmlSaveDir\n",
    "    global SQL_Conn\n",
    "    global reference_df\n",
    "    \n",
    "    EMB_DIM = emb_dim\n",
    "    DATA_LOC = _DATA_LOC\n",
    "    subDIR = _subDIR\n",
    "    \n",
    "    df_1 = pd.read_csv(os.path.join(DATA_LOC,subDIR,'train_data.csv'), index_col=None)\n",
    "    df_2 = pd.read_csv(os.path.join(DATA_LOC,subDIR,'test_data.csv'), index_col=None)\n",
    "    reference_df = df_1.append(df_2,ignore_index=True)\n",
    "    \n",
    "    SQL_Conn = sqlite.get_engine()\n",
    "    if _htmlSaveDir is None:\n",
    "        htmlSaveDir = './htmlCache'\n",
    "    else:\n",
    "        htmlSaveDir = _htmlSaveDir\n",
    "    Path(htmlSaveDir).mkdir(exist_ok=True,parents=True )\n",
    "    \n",
    "    redis_obj.ingest_record_data(\n",
    "        DATA_LOC=DATA_LOC,\n",
    "        subDIR=subDIR\n",
    "    )\n",
    "    \n",
    "    redis_obj.ingest_MP2V_embeddings(\n",
    "        DATA_LOC,\n",
    "        subDIR ,\n",
    "        mp2v_emb_dir,\n",
    "        emb_dim=emb_dim\n",
    "    )\n",
    "    return \n",
    "\n",
    "\n",
    "# --------------------\n",
    "# Helper function\n",
    "# --------------------\n",
    "def get_comparison_vecotors(record_row, domain, entity_list):\n",
    "    global redis_obj\n",
    "    global EMB_DIM\n",
    "    \n",
    "    emb_dim = EMB_DIM\n",
    "    vec = []\n",
    "    for entity_id in entity_list:\n",
    "        key = 'mp2v_{}_{}_{}'.format(emb_dim, domain, entity_id)\n",
    "        vec.append(redis_obj.fetch_np(key))\n",
    "    \n",
    "    key = 'mp2v_{}_{}_{}'.format(emb_dim, domain,record_row[domain])\n",
    "    target_entity_vec = redis_obj.fetch_np(key)\n",
    "    vec.append(target_entity_vec)\n",
    "    return (domain, np.array([target_entity_vec]), np.array(vec))\n",
    "\n",
    "\n",
    "# ===========================================\n",
    "# Return ::\n",
    "# Dict of { <domain> : html_string of figure }\n",
    "#\n",
    "# ===========================================\n",
    "\n",
    "def get_stackedComparisonPlots(\n",
    "    record_id, \n",
    "    min_count = 1000,\n",
    "    return_type=1\n",
    "):\n",
    "    global EMB_DIM\n",
    "    global htmlSaveDir\n",
    "    global SQL_Conn\n",
    "    global DATA_LOC \n",
    "    global reference_df\n",
    "    global subDIR \n",
    "    global redis_obj\n",
    "    \n",
    "    \n",
    "    with open(os.path.join(DATA_LOC, subDIR,'col_val2id_dict.pkl'), 'rb') as fh:\n",
    "            column_values2id = pickle.load(fh)\n",
    "    column_id2value = { _domain: {v:k for k,v in _dict.items()} for _domain,_dict in column_values2id.items()  }\n",
    "\n",
    "    with open(os.path.join(DATA_LOC, subDIR,'domain_dims.pkl'), 'rb') as fh:\n",
    "            domain_dims = pickle.load(fh)\n",
    "\n",
    "    record_row = redis_obj.fetch_data(record_id)\n",
    "    print(record_row)\n",
    "    record_row_w_vals = {} \n",
    "    for _domain in column_values2id.keys():\n",
    "        record_row_w_vals[_domain] = column_id2value[_domain][record_row[_domain]]\n",
    "\n",
    "    _query_str_0 = 'select PanjivaRecordID from Records where ConsigneePanjivaID={} and ShipperPanjivaID={}'.format(\n",
    "        record_row_w_vals['ConsigneePanjivaID'],record_row_w_vals['ShipperPanjivaID']\n",
    "    )\n",
    "    _query_str_1 = 'select PanjivaRecordID from Records where ConsigneePanjivaID={} or ShipperPanjivaID={}'.format(\n",
    "        record_row_w_vals['ConsigneePanjivaID'],record_row_w_vals['ShipperPanjivaID']\n",
    "    )\n",
    "\n",
    "    _query_str_6= 'select PanjivaRecordID from Records where PortOfLading=\"{}\" and HSCode={} and  PortOfUnlading=\"{}\"'.format(\n",
    "        record_row_w_vals['PortOfLading'],record_row_w_vals['HSCode'], record_row_w_vals['PortOfUnlading']\n",
    "    )\n",
    "    _query_str_4 = 'select PanjivaRecordID from Records where ( ShipmentOrigin=\"{}\" and PortOfLading=\"{}\")  or (ShipmentDestination=\"{}\" and PortOfUnlading=\"{}\")'.format(\n",
    "        record_row_w_vals['ShipmentOrigin'], \n",
    "        record_row_w_vals['PortOfUnlading'],\n",
    "        record_row_w_vals['ShipmentDestination'],\n",
    "        record_row_w_vals['PortOfLading'] \n",
    "    )\n",
    "\n",
    "    _query_str_5 = 'select PanjivaRecordID from Records where ( ShipmentOrigin=\"{}\" and HSCode={})  or (ShipmentDestination=\"{}\" and HSCode={})'.format(\n",
    "        record_row_w_vals['ShipmentOrigin'], \n",
    "        record_row_w_vals['HSCode'],\n",
    "        record_row_w_vals['ShipmentDestination'],\n",
    "        record_row_w_vals['HSCode'] \n",
    "    )\n",
    "\n",
    "    _query_str_2 = 'select PanjivaRecordID from Records where ShipperPanjivaID={} and ShipmentOrigin=\"{}\"'.format(\n",
    "        record_row_w_vals['ShipperPanjivaID'], record_row_w_vals['ShipmentOrigin']\n",
    "    )\n",
    "\n",
    "    _query_str_3 = 'select PanjivaRecordID from Records where ConsigneePanjivaID={} and  ShipmentDestination=\"{}\"'.format(\n",
    "        record_row_w_vals['ConsigneePanjivaID'], record_row_w_vals['ShipmentDestination']\n",
    "    )\n",
    "\n",
    "    query_string_list = [_query_str_0, _query_str_1, _query_str_2,_query_str_3,  _query_str_4, _query_str_5, _query_str_6 ]\n",
    "\n",
    "\n",
    "    data = None\n",
    "    ID_COL = 'PanjivaRecordID'\n",
    "\n",
    "    for _query in query_string_list:\n",
    "        _df = pd.read_sql(\n",
    "                _query,\n",
    "                con=SQL_Conn,\n",
    "                index_col=None\n",
    "        )\n",
    "\n",
    "        ids = _df[ID_COL].values.tolist()\n",
    "        tmp = reference_df.loc[reference_df[ID_COL].isin(ids)]\n",
    "        if data is None:\n",
    "            data = tmp.copy()\n",
    "        data = data.append(tmp,ignore_index=True)\n",
    "        data = data.drop_duplicates(subset=[ID_COL])\n",
    "        if len(data) >= min_count:\n",
    "            data = data.head(min_count)\n",
    "            break\n",
    "        \n",
    "    vectors_dict = {}\n",
    "    for domain in domain_dims.keys():\n",
    "        if domain in ['ConsigneePanjivaID','ShipperPanjivaID']:\n",
    "            continue\n",
    "        entity_list = data[domain].values.tolist()\n",
    "        vectors = get_comparison_vecotors( record_row, domain, entity_list )\n",
    "        vectors_dict[vectors[0]] = (vectors[1], vectors[2])\n",
    "\n",
    "    # -----------------------------------------------------------------------------------\n",
    "    fig = make_subplots(rows=2, cols=3, subplot_titles= list(vectors_dict.keys()))\n",
    "    i = 1\n",
    "    j = 1\n",
    "    fig_dict = {}\n",
    "    bg_colors = [\n",
    "        'rgba(252, 240, 247,0.35)',\n",
    "        'rgba(232, 244, 255,0.25)',\n",
    "        'rgba(232, 255, 252,0.35)',\n",
    "        'rgba(230, 248, 248,0.25)',\n",
    "        'rgba(251, 255, 232,0.35)',\n",
    "        'rgba(252, 251, 232,0.25)'\n",
    "    ]\n",
    "    i = 0\n",
    "    for domain in domain_dims.keys():\n",
    "        if domain not in vectors_dict.keys():\n",
    "            continue\n",
    "         \n",
    "        target_entity_vec = vectors_dict[domain][0]\n",
    "        _vectors = vectors_dict[domain][1]\n",
    "        \n",
    "        fig = px.density_contour(\n",
    "            x = _vectors[:,0],\n",
    "            y = _vectors[:,1]\n",
    "        )\n",
    "\n",
    "       \n",
    "        fig.update_layout(showlegend=False)\n",
    "        sub_figure = go.Scatter(\n",
    "            x = _vectors[:,0],\n",
    "            y = _vectors[:,1],\n",
    "            mode = 'markers',\n",
    "            marker = dict(\n",
    "                color = 'rgb(163, 255, 71,0.20)',\n",
    "                size = 10,\n",
    "                line=dict(\n",
    "                color='MediumPurple',\n",
    "                    width=2\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "            x=target_entity_vec[:,0],\n",
    "            y=target_entity_vec[:,1],\n",
    "            mode=\"markers+text\",\n",
    "            marker = dict(\n",
    "                color = 'rgba(230,0,10,0.95)',\n",
    "                size = 15,\n",
    "                line=dict(\n",
    "                color='Yellow',\n",
    "                    width=2\n",
    "                )\n",
    "            ),\n",
    "            text=[\"Entity\"],\n",
    "            )\n",
    "        )\n",
    "        range_x = np.max(_vectors[:,0]) - np.min(_vectors[:,0])\n",
    "        range_y = np.max(_vectors[:,1]) - np.min(_vectors[:,1])\n",
    "        r1 = 0.04*range_x\n",
    "        r2 = 0.04*range_y\n",
    "        x0 =target_entity_vec[:,0][0]\n",
    "        y0 =target_entity_vec[:,1][0]\n",
    "        x1 = x0 - r1\n",
    "        x2 = x0 + r1\n",
    "        y1 = y0 - r2\n",
    "        y2 = y0 + r2\n",
    "        print(x1,x2,y1,y2)\n",
    "        fig.add_shape(\n",
    "            type=\"rect\",\n",
    "            x0=x1, y0=y1, x1=x2, y1=y2,\n",
    "            line=dict( width=2, color=\"rgba(230,0,10,0.95)\"),\n",
    "        )\n",
    "            \n",
    "        fig.add_trace(\n",
    "            sub_figure\n",
    "        )\n",
    "        fig.update_xaxes(tickfont=dict(color='black', size=15))\n",
    "        fig.update_yaxes(tickfont=dict(color='black', size=15))\n",
    "        fig.update_layout(showlegend=False)\n",
    "        \n",
    "        \n",
    "        layout = Layout(\n",
    "            paper_bgcolor=bg_colors[i],\n",
    "            plot_bgcolor='rgba(0,0,0,0.05)'\n",
    "        )\n",
    "\n",
    "        fig.update_layout(layout)\n",
    "        fig.update_layout(xaxis_showgrid=True, yaxis_showgrid=True)\n",
    "        fig.update_layout(height=300, width=360)\n",
    "        fig.update_layout(margin = dict(t=0, l=0, r=0, b=0))\n",
    "        fig_dict[domain] = fig\n",
    "        i+=1\n",
    "    if return_type==1:\n",
    "        result = {}\n",
    "        for domain,fig_obj in fig_dict.items():\n",
    "            result[domain] = io.to_html(fig_obj, include_plotlyjs='cdn', include_mathjax='cdn', full_html=False)\n",
    "        return result\n",
    "    else:\n",
    "        return fig_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "authorized-disability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already present!\n"
     ]
    }
   ],
   "source": [
    "     \n",
    "# ===========================\n",
    "# Example code\n",
    "# ===========================\n",
    "\n",
    "# initialize(\n",
    "#     _DATA_LOC = './../generated_data_v1/us_import',\n",
    "#     _subDIR = '01_2016',\n",
    "#     mp2v_emb_dir = './../records2graph/saved_model_data',\n",
    "#     emb_dim = 64,\n",
    "#     _htmlSaveDir = './htmlCache'\n",
    "# )\n",
    "# fig_dict = get_stackedComparisonPlots(\n",
    "#     record_id='121888536', \n",
    "#     min_count = 1000, \n",
    "#     return_type=1\n",
    "# )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "colored-designer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PanjivaRecordID': 121888536, 'Carrier': 336, 'ConsigneePanjivaID': 2225, 'HSCode': 92, 'PortOfLading': 243, 'PortOfUnlading': 44, 'ShipmentDestination': 9, 'ShipmentOrigin': 112, 'ShipperPanjivaID': 1230}\n",
      "7.19963812828064 8.62789273262024 -38.6585365486145 -36.26982343673706\n",
      "-23.412688064575196 -23.240414810180663 -5.9474038314819335 -5.768507080078125\n",
      "8.303452243804932 8.520919094085693 -17.118056030273436 -16.622144012451173\n",
      "-6.286534996032715 -6.144424705505371 -7.0393485260009765 -6.968369560241699\n",
      "20.89486892700195 21.183843536376955 -35.281813354492186 -35.04203155517578\n",
      "22.12728485107422 22.297550354003906 -24.692617340087892 -24.5274983215332\n"
     ]
    }
   ],
   "source": [
    "# fig_dict = get_stackedComparisonPlots(\n",
    "#     record_id='121888536', \n",
    "#     min_count = 1000, \n",
    "#     return_type=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "structural-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d,f in fig_dict.items():\n",
    "    plotly.offline.plot(f, filename = 'sc_{}.html'.format(d), auto_open=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "27874166\n",
    "4549330.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
