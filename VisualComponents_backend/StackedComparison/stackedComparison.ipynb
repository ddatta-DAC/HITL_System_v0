{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "mediterranean-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('./../..')\n",
    "sys.path.append('./..')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append('./../..')\n",
    "from redisStore import redisUtil\n",
    "from pathlib import Path\n",
    "import plotly\n",
    "from plotly import express as px\n",
    "import os\n",
    "import plotly.io as pio\n",
    "import pickle\n",
    "from DB_Ingestion.sqlite_engine import sqlite\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from sqlalchemy import create_engine\n",
    "from plotly import io\n",
    "\n",
    "DATA_LOC = None\n",
    "subDIR = None\n",
    "# Singleton object\n",
    "redis_obj = redisUtil.redisStore\n",
    "EMB_DIM = None\n",
    "htmlSaveDir = None\n",
    "SQL_Conn = None\n",
    "\n",
    "\n",
    "\n",
    "# =============================\n",
    "#  This needs to be called to ingest data into redis,\n",
    "# =============================\n",
    "def initialize(\n",
    "    _DATA_LOC,\n",
    "    _subDIR,\n",
    "    mp2v_emb_dir = './../records2graph/saved_model_data',\n",
    "    emb_dim = 64,\n",
    "    _htmlSaveDir = None\n",
    "):\n",
    "    global redis_obj\n",
    "    global DATA_LOC\n",
    "    global subDIR\n",
    "    global EMB_DIM\n",
    "    global htmlSaveDir\n",
    "    global SQL_Conn\n",
    "    \n",
    "    \n",
    "    EMB_DIM = emb_dim\n",
    "    DATA_LOC = _DATA_LOC\n",
    "    subDIR = _subDIR\n",
    "    if _htmlSaveDir is None:\n",
    "        htmlSaveDir = './htmlCache'\n",
    "    else:\n",
    "        htmlSaveDir = _htmlSaveDir\n",
    "    Path(htmlSaveDir).mkdir(exist_ok=True,parents=True )\n",
    "    \n",
    "    redis_obj.ingest_record_data(\n",
    "        DATA_LOC=DATA_LOC,\n",
    "        subDIR=subDIR\n",
    "    )\n",
    "    \n",
    "    redis_obj.ingest_MP2V_embeddings(\n",
    "        DATA_LOC,\n",
    "        subDIR ,\n",
    "        mp2v_emb_dir,\n",
    "        emb_dim=emb_dim\n",
    "    )\n",
    "    return \n",
    "\n",
    "\n",
    "# --------------------\n",
    "# Helper function\n",
    "# --------------------\n",
    "def get_comparison_vecotors(record_row, domain, entity_list):\n",
    "    global redis_obj\n",
    "    global EMB_DIM\n",
    "\n",
    "    emb_dim = EMB_DIM\n",
    "    vec = []\n",
    "    for entity_id in entity_list:\n",
    "        key = 'mp2v_{}_{}_{}'.format(emb_dim, domain, entity_id)\n",
    "        vec.append(redis_obj.fetch_np(key))\n",
    "    \n",
    "    key = 'mp2v_{}_{}_{}'.format(emb_dim, domain,record_row[domain])\n",
    "    target_entity_vec = redis_obj.fetch_np(key)\n",
    "    vec.append(target_entity_vec)\n",
    "    return (domain, np.array([target_entity_vec]), np.array(vec))\n",
    "\n",
    "    \n",
    "\n",
    "def get_stackedComparisonPlots(\n",
    "    record_id, \n",
    "    min_count = 1000\n",
    "    return_type=1\n",
    "):\n",
    "    global EMB_DIM\n",
    "    global htmlSaveDir\n",
    "    global SQL_Conn\n",
    "    global DATA_LOC \n",
    "    global subDIR = '01_2016'\n",
    "    with open(os.path.join(DATA_LOC, subDIR,'col_val2id_dict.pkl'), 'rb') as fh:\n",
    "            column_values2id = pickle.load(fh)\n",
    "    column_id2value = { _domain: {v:k for k,v in _dict.items()} for _domain,_dict in column_values2id.items()  }\n",
    "\n",
    "    with open(os.path.join(DATA_LOC, subDIR,'domain_dims.pkl'), 'rb') as fh:\n",
    "            domain_dims = pickle.load(fh)\n",
    "\n",
    "    record_row = redis_obj.fetch_data(record_id)\n",
    "    record_row_w_vals = {} \n",
    "    for _domain in column_values2id.keys():\n",
    "        record_row_w_vals[_domain] = column_id2value[_domain][record_row[_domain]]\n",
    "\n",
    "    _query_str_0 = 'select PanjivaRecordID from Records where ConsigneePanjivaID={} and ShipperPanjivaID={}'.format(\n",
    "        record_row_w_vals['ConsigneePanjivaID'],record_row_w_vals['ShipperPanjivaID']\n",
    "    )\n",
    "    _query_str_1 = 'select PanjivaRecordID from Records where ConsigneePanjivaID={} or ShipperPanjivaID={}'.format(\n",
    "        record_row_w_vals['ConsigneePanjivaID'],record_row_w_vals['ShipperPanjivaID']\n",
    "    )\n",
    "\n",
    "    _query_str_6= 'select PanjivaRecordID from Records where PortOfLading=\"{}\" and HSCode={} and  PortOfUnlading=\"{}\"'.format(\n",
    "        record_row_w_vals['PortOfLading'],record_row_w_vals['HSCode'], record_row_w_vals['PortOfUnlading']\n",
    "    )\n",
    "    _query_str_4 = 'select PanjivaRecordID from Records where ( ShipmentOrigin=\"{}\" and PortOfLading=\"{}\")  or (ShipmentDestination=\"{}\" and PortOfUnlading=\"{}\")'.format(\n",
    "        record_row_w_vals['ShipmentOrigin'], \n",
    "        record_row_w_vals['PortOfUnlading'],\n",
    "        record_row_w_vals['ShipmentDestination'],\n",
    "        record_row_w_vals['PortOfLading'] \n",
    "    )\n",
    "\n",
    "    _query_str_5 = 'select PanjivaRecordID from Records where ( ShipmentOrigin=\"{}\" and HSCode={})  or (ShipmentDestination=\"{}\" and HSCode={})'.format(\n",
    "        record_row_w_vals['ShipmentOrigin'], \n",
    "        record_row_w_vals['HSCode'],\n",
    "        record_row_w_vals['ShipmentDestination'],\n",
    "        record_row_w_vals['HSCode'] \n",
    "    )\n",
    "\n",
    "    _query_str_2 = 'select PanjivaRecordID from Records where ShipperPanjivaID={} and ShipmentOrigin=\"{}\"'.format(\n",
    "        record_row_w_vals['ShipperPanjivaID'], record_row_w_vals['ShipmentOrigin']\n",
    "    )\n",
    "\n",
    "    _query_str_3 = 'select PanjivaRecordID from Records where ConsigneePanjivaID={} and  ShipmentDestination=\"{}\"'.format(\n",
    "        record_row_w_vals['ConsigneePanjivaID'], record_row_w_vals['ShipmentDestination']\n",
    "    )\n",
    "\n",
    "    query_string_list = [_query_str_0, _query_str_1, _query_str_2,_query_str_3,  _query_str_4, _query_str_5, _query_str_6 ]\n",
    "\n",
    "    df_1 = pd.read_csv(os.path.join(DATA_LOC,subDIR,'train_data.csv'), index_col=None)\n",
    "    df_2 = pd.read_csv(os.path.join(DATA_LOC,subDIR,'test_data.csv'), index_col=None)\n",
    "    reference_df = df_1.append(df_2,ignore_index=True)\n",
    "\n",
    "    data = None\n",
    "    ID_COL = 'PanjivaRecordID'\n",
    "\n",
    "    for _query in query_string_list:\n",
    "\n",
    "        _df = pd.read_sql(\n",
    "                _query,\n",
    "                con=SQL_Conn,\n",
    "                index_col=None\n",
    "        )\n",
    "\n",
    "        ids = _df[ID_COL].values.tolist()\n",
    "        tmp = reference_df.loc[reference_df[ID_COL].isin(ids)]\n",
    "        if data is None:\n",
    "            data = tmp.copy()\n",
    "        data = data.append(tmp,ignore_index=True)\n",
    "        data = data.drop_duplicates(subset=[ID_COL])\n",
    "        if len(data) >= min_count:\n",
    "            data = data.head(min_count)\n",
    "            break\n",
    "\n",
    "    vectors_dict = {}\n",
    "    for domain in domain_dims.keys():\n",
    "        if domain in ['ConsigneePanjivaID','ShipperPanjivaID']:\n",
    "            continue\n",
    "        entity_list = data[domain].values.tolist()\n",
    "        vectors = get_comparison_vecotors( record_row, domain, entity_list )\n",
    "        vectors_dict[vectors[0]] = (vectors[1], vectors[2])\n",
    "\n",
    "    # -----------------------------------------------------------------------------------\n",
    "    fig = make_subplots(rows=2, cols=3, subplot_titles= list(vectors_dict.keys()))\n",
    "    i = 1\n",
    "    j = 1\n",
    "\n",
    "    for domain in domain_dims.keys():\n",
    "        if domain not in vectors_dict.keys():\n",
    "            continue\n",
    "        target_entity_vec = vectors_dict[domain][0]\n",
    "        _vectors = vectors_dict[domain][1]\n",
    "        # fig = px.scatter(_vectors[:,0], _vectors[:,1])\n",
    "        sub_figure = go.Scatter(\n",
    "            x = _vectors[:,0],\n",
    "            y = _vectors[:,1],\n",
    "            mode = 'markers',\n",
    "            marker = dict(\n",
    "                color = 'rgba(10,0,225,0.5)',\n",
    "                size = 6\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            sub_figure,\n",
    "            row=i, col=j\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Histogram2dContour(\n",
    "                x = _vectors[:,0],\n",
    "                y = _vectors[:,1],\n",
    "                colorscale = 'Greens',\n",
    "                opacity=0.45,\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=i, col=j\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "            x=target_entity_vec[:,0],\n",
    "            y=target_entity_vec[:,1],\n",
    "            mode=\"markers+text\",\n",
    "            marker = dict(\n",
    "            color = 'rgba(230,0,10,0.85)',\n",
    "                size = 10\n",
    "            ),\n",
    "            text=[\"Record Entity\"],\n",
    "            ),\n",
    "        row=i, col=j\n",
    "        )\n",
    "        fig.update_coloraxes({'showscale':False}, row=i, col=j)\n",
    "        fig.update_traces(showlegend=False,  row=i, col=j)\n",
    "        j+=1\n",
    "        if j > 3:\n",
    "            j=1\n",
    "            i+= 1\n",
    "    fig.update_layout(xaxis_showgrid=False, yaxis_showgrid=False)\n",
    "    fig.update(layout_coloraxis_showscale=False)\n",
    "    fig.update_coloraxes({'showscale':False})\n",
    "    \n",
    "    if return_type == 1:\n",
    "        html_String = io.to_html(fig, include_plotlyjs='cdn', include_mathjax='cdn', full_html=False)\n",
    "        return html_String\n",
    "    elif return_type == 2:\n",
    "        fpath = os.path.join(htmlSaveDir,'stackedComaprison_{}.html'.format(record_id))\n",
    "        fig.write_html(fpath,include_plotlyjs='cdn',include_mathjax='cdn',full_html=False)\n",
    "        return fpath\n",
    "        \n",
    "        \n",
    "# ===========================\n",
    "'''\n",
    "initialize(\n",
    "    _DATA_LOC = './../../generated_data_v1/us_import',\n",
    "    _subDIR = '01_2016',\n",
    "    mp2v_emb_dir = './../../records2graph/saved_model_data',\n",
    "    emb_dim = 64,\n",
    "    _htmlSaveDir = './htmlCache'\n",
    ")\n",
    "\n",
    "get_stackedComparisonPlots(\n",
    "    record_id, \n",
    "    min_count = 500\n",
    ")\n",
    "\n",
    "\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
